{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run selenium and chrome driver to scrape data from cloudbytes.dev\n",
    "import time\n",
    "import os.path\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.headless = True # Ensure GUI is off\n",
    "# chrome_options.add_argument(\"--window-size=1920,1200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to chromedriver as per your configuration\n",
    "homedir = os.path.expanduser(\"~\")\n",
    "webdriver_service = Service(f\"{homedir}/ao3lockwood-co/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Chrome Browser\n",
    "browser = webdriver.Chrome(service=webdriver_service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get page\n",
    "pagenum=1\n",
    "link=\"https://archiveofourown.org/tags/Lockwood%20*a*%20Co*d*%20-%20Jonathan%20Stroud/works?page=\"+str(pagenum)\n",
    "#link=\"https://archiveofourown.org/tags/Lockwood%20*a*%20Co*d*%20-%20Jonathan%20Stroud/works?page=1\"\n",
    "browser.get(link)\n",
    "\n",
    "maxpagenum=int(browser.find_element(By.XPATH,'//ol[1]/li[13]').text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(browser):\n",
    "    # Find all the fanfic works on the page\n",
    "    works = browser.find_elements(By.XPATH, '//ol[2]/li')\n",
    "    # Iterate through each work and extract author and datetime\n",
    "    data=[]\n",
    "    for work in works:\n",
    "        h4 = work.find_element(By.TAG_NAME,'h4')\n",
    "        a = h4.find_elements(By.TAG_NAME, 'a')\n",
    "        links = a[0].get_attribute(\"href\")\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from the first page\n",
    "links_list=get_links(browser)\n",
    "#Wait for 10 seconds\n",
    "time.sleep(10)\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(links_list):\n",
    "    data=[]\n",
    "    counter=0\n",
    "    for x in links_list:\n",
    "        newlink=x+'?view_adult=true'\n",
    "        counter+=1\n",
    "        print(f\"getting missing data {counter}/{len(links_list)}\")\n",
    "        source = requests.get(newlink, headers={\n",
    "                          'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64)'}).text\n",
    "        soup = BeautifulSoup(source,'html.parser')\n",
    "        title=soup.find('h2', attrs={'class':'title heading'}).get_text().replace('\\n','').strip()\n",
    "        try:\n",
    "            author=soup.find('a', attrs={'rel':'author'}).get_text()\n",
    "        except:\n",
    "            author=\"Anonymous\"\n",
    "        datetime=soup.find('dd', attrs={'class':'published'}).get_text()\n",
    "        chapters=soup.find('dd', attrs={'class':'chapters'}).get_text()\n",
    "        language=soup.find('dd', attrs={'class':'language'}).get_text().replace('\\n','').strip()\n",
    "        words=soup.find('dd', attrs={'class':'words'}).get_text()\n",
    "        try:\n",
    "            kudos=soup.find('dd', attrs={'class':'kudos'}).get_text()\n",
    "        except:\n",
    "            kudos=0\n",
    "        try:\n",
    "            comments=soup.find('dd', attrs={'class':'comments'}).get_text()\n",
    "        except:\n",
    "            comments=0\n",
    "        try:\n",
    "            bookmarks=soup.find('dd', attrs={'class':'bookmarks'}).get_text()\n",
    "        except:\n",
    "            bookmarks=0\n",
    "        try:\n",
    "            hits=soup.find('dd', attrs={'class':'hits'}).get_text()\n",
    "        except:\n",
    "            hits=0\n",
    "        warning=soup.find('dd', attrs={'class':'warning tags'}).get_text().replace('\\n','').strip()\n",
    "        try:\n",
    "            ships = soup.find('dd', attrs={'class':'relationship tags'})\n",
    "            ships_list=ships.find_all('a', attrs={'class':'tag'})\n",
    "            mainrelationship = ships_list[0].get_text().strip()\n",
    "            relationship_list = []\n",
    "            for r in ships_list:\n",
    "                relationship_list.append(r.get_text().strip())\n",
    "        except:\n",
    "            mainrelationship='None'\n",
    "            relationship_list = []\n",
    "        try:\n",
    "            char = soup.find('dd', attrs={'class':'character tags'})\n",
    "            char_list=char.find_all('a', attrs={'class':'tag'})\n",
    "            character_list = []\n",
    "            for c in char_list:\n",
    "                character_list.append(c.get_text().strip())\n",
    "        except:\n",
    "            character_list=[]\n",
    "        try:\n",
    "            freeform = soup.find('dd', attrs={'class':'freeform tags'})\n",
    "            freefom_list=freeform.find_all('a', attrs={'class':'tag'})\n",
    "            tags_list = []\n",
    "            for t in freefom_list:\n",
    "                tags_list.append(t.get_text().strip())\n",
    "        except:\n",
    "            tags_list = []\n",
    "        try:\n",
    "            summary=soup.find('div', attrs={'class':'summary module'}).get_text().replace('\\n', ' ').replace('Summary:','').strip()\n",
    "        except:\n",
    "            summary=np.nan\n",
    "        rating_tag=soup.find('dd', attrs={'class':'rating tags'}).get_text().replace('\\n','').strip()\n",
    "        row = {'link':x, \n",
    "               'title':title,\n",
    "               'author':author, \n",
    "               'updatedate':datetime,\n",
    "               'chapters':chapters,\n",
    "               'language':language,\n",
    "               'words':words,\n",
    "               'kudos':kudos, \n",
    "               'comments':comments,\n",
    "               'bookmarks':bookmarks,\n",
    "               'hits':hits,\n",
    "               'warning':warning,\n",
    "               'mainship':mainrelationship,\n",
    "               'relationship':relationship_list,\n",
    "               'characters':character_list, \n",
    "               'tags':tags_list,\n",
    "               'summary':summary,\n",
    "               'rating':rating_tag\n",
    "               }\n",
    "        #print(row)\n",
    "        data.append(row)\n",
    "        time.sleep(10)\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=get_data(links_list)\n",
    "# Split the chapter column into chapter and chapter_max, and create a completion column\n",
    "final[['chapter','chapter_max']] = final.chapters.str.split(\"/\", expand=True)\n",
    "final['completion'] = final.apply(lambda row: 'completed' if row['chapter']==row['chapter_max'] else 'incomplete', axis=1)\n",
    "final.to_csv.to_csv('ao3_lockwood_and_co.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimal_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
